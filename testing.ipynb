{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging Face tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234f8f6c2e1644339bc532b6b57c7a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ariel\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ariel\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb61678f7cf4610acbfe7e5e0cdd0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d733d8e020b14d5099a167487e9fd200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720e2eeba114416192c26891f17f39cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to microsoft/DialoGPT-medium and revision 8bada3b (https://huggingface.co/microsoft/DialoGPT-medium).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4220cfae364e6e8fce5ab4515327c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be37889a05c484eb3675de6d8e2eae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600b972256a44ccc8618a3a2eb9e33a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bc8993ffe844a6b8214b08dbf6bfef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee717a2c27a649c6a9068ad5bc22f721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f8b06cec0447e8b2b6e843d9ee70ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conversation id: 4afc7941-7b61-4e67-ab69-e21782c97f87\n",
       "user: Please recombine the four following facts into a single fact using only two lines of text: 1. Crocodiles are 10 meters long 2. The scales of crocodiles are green and tough 3. The longest crocodile is 15 meters long, but on average they can reach 10 meters. 4. From head to tip, crocodiles can measure ten meters\n",
       "assistant: I like this idea."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, Conversation\n",
    "converse = pipeline(\"conversational\")\n",
    "\n",
    "conversation_1 = Conversation(\"Please recombine the four following facts into a single fact using only two lines of text: 1. Crocodiles are 10 meters long 2. The scales of crocodiles are green and tough 3. The longest crocodile is 15 meters long, but on average they can reach 10 meters. 4. From head to tip, crocodiles can measure ten meters\")\n",
    "converse([conversation_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ariel\\Documents\\PhD Main Folder\\Year 1\\artificial-languages\\testing.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msk-4f3iSqeVRzDuG5QeLjsGT3BlbkFJiOtGiJ7Aund2DYVyI4pV\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msay this is a test\u001b[39;49m\u001b[39m\"\u001b[39;49m}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"say this is a test\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75d1acfd7414795834f5987aa2774c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463c54f3b92f47e7a1ff814ff83c9bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d2d626e5994ce28d973eb2df838184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/58.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14fd996d041471e99ec59b0e127379c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/66.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6856afcf87184f24ac727e6f163adee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c701fa67b6d14d53bf4498674f26b8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/69.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0fbc4cf5ec47899c28865cfbcef383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9f8a725f1742b7a587d1d4885dad06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cab0274ad74b80bec06acc498d8de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5622 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea25e57de194c3cbbd7a71fdb26d9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5622 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"multi_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary'],\n",
       "        num_rows: 44972\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary'],\n",
       "        num_rows: 5622\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary'],\n",
       "        num_rows: 5622\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GAITHERSBURG, Md. (AP) — A small, private jet has crashed into a house in Maryland\\'s Montgomery County on Monday, killing at least three people on board, authorities said. \\n \\n Preliminary information indicates at least three people were on board and didn\\'t survive the Monday crash into home in Gaithersburg, a Washington, D.C. suburb, said Pete Piringer, a Montgomery County Fire and Rescue spokesman. \\n \\n He said a fourth person may have been aboard. \\n \\n Piringer said the jet crashed into one home around 11 a.m., setting it and two others on fire. Crews had the fire under control within an hour and were searching for anyone who may have been in the homes. \\n \\n Television news footage of the scene showed one home nearly destroyed, with a car in the driveway. Witnesses told television news crews that they saw the airplane appear to struggle to maintain altitude before going into a nosedive and crashing. \\n \\n An FAA spokesman said preliminary information shows the Embraer EMB-500/Phenom 100 twin-engine jet was on approach at the nearby Montgomery County Airpark. The National Transportation Safety Board is sending an investigator to the scene. ||||| Gemmell family (Photo: Facebook) \\n \\n GAITHERSBURG, Md. (WUSA9) -- The investigations into a plane crash that left six people dead in Gaithersburg on Monday evening are just beginning. \\n \\n A mother and her two young children are three of the six lives lost in the crash. \\n \\n Marie Gemmell, 36, her three-year-old son Cole and her infant-son Devin were inside their home when a corporate jet crashed into it. Their bodies were found on the second floor hours after the crash. The father and a third child were not home at the time of the crash. \\n \\n Michael Rosenberg was on the jet that crashed (Photo: Health Decisions) \\n \\n Three people on the jet were also killed, according to Montgomery County fire officials. One of those victims has been identified as Michael Rosenberg, CEO of Health Decisions. You can read their statement here. \\n \\n An Embraer EMB-500/Phenom 100 crashed into a house in the 19700 block of Drop Forge Lane off Snouffer School Road in the neighborhood of Hunters Woods around 10:45 a.m., according to the NTSB. The plane was coming from Chapel Hill, NC and approaching the Montgomery County Air Park. \\n \\n The NTSB has sent a go-team to the site, where three homes were damaged. Firefighters used foam to battle fires all around the scene. The fuselage of the jet is parallel to a second house, and the tail of the airplane is at the front door. One of the wings was catapulted into the Gemmell\\'s house, causing a huge fire and the majority of the damage, according to the NTSB. Senior Investigator Timothy LeBaron is leading the go-team. \\n \\n Investigators are looking at operations, including crew experience, training and procedures, the functionality of the engines, the weather, air traffic control and more, NTSB spokesperson Robert L. Sumwalt said at a press confrence. \\n \\n \"Our mission is to find out not only what happened, but why it happened because we want to make sure something like this never happens again,\" Sumwalt said. \\n \\n MORE: Woman says community feared plane crash \\n \\n \\n \\n NTSB investigators are currently collecting perishable evidence, not determining the cause. They\\'ll be conducting interviews and documenting the wreckage. Investigators could be on the scene for three to seven days for what they call the \"fact-finding\" phase. \\n \\n The black box, which has recordings from the crash, has been recovered. It is in good condition and has been rushed to labs, Sumwalt said. \\n \\n The first call about the crash came in at 10:44 a.m. from the National Guard Armory for the report of an explosion, and units were on the scene in approximately seven minutes, Montgomery County Fire Chief Steve Lohr said at an initial press conference. Utility crews were also on the scene and Lorh said it is safe for residents in the area. Electricity has been temporarily cut off. \\n \\n Recordings of the 911-calls from the crash were released on Monday evening. In the recordings neighbors and witnesses describe the scene where the plane crashed in the Gaithersburg neighborhood. \\n \\n Recordings of the 911 calls from the Gaithersburg plane crash were released on Monday evening. \\n \\n \"We just heard a giant explosion we looked out the window and there\\'s... it looks like a house is on fire, we\\'ve got some people running over there to see if people are okay,\" one caller described. \\n \\n \\n \\n RAW: Fire Chief Steve Lohr speaks on plane crash \\n \\n A woman who was traveling into the area after taking a test at Montgomery College tells WUSA9 that she could see the smoke from the crash from I-370. As she got closer, she saw all the emergency response vehicles and called her husband. He told her that the smoke was coming from the area where her mother and stepfather lived and she says she got worried. She discovered the house that was struck was their neighbors\\' house. She says there are \"three little ones\" who live in that house. \\n \\n One person reported seeing the plane \"wobble\" before it crashed into the house. Other neighbors reported hearing repeated booms and feeling their houses shake from the impact of the plane. \\n \\n Something went wrong with the jet heading to the Montgomery County airport and it went into a house in Gaithersburg \\n \\n WUSA9 spoke with an eyewitness named Jocelyn Brown who said she first heard the plane sputtering, making a sound that planes that go over the area normally don\\'t make flying over the houses. She says she and her mother became concerned and went to investigate. They then saw the plane hit the side of a house. She reported seeing a \"mushroom effect of smoke\" and also hearing three explosions after the plane hit. \\n \\n Jocelyn says they also heard screams in the area of the home. She says she does not know whether they were coming from inside the house or behind them. \\n \\n Jocelyn lives in the area and says she knows the mother that lives there. She described her as a \"sweet woman\" who walks with her kids in the area all the time and speaks to everyone. \\n \\n He said the plane sounded like it was \"puttering\" and then saw fire \\n \\n A woman posted video from the ground of the scene of the plane crash on YouTube. \\n \\n . \\n \\n The FAA has released the following information: \\n \\n \"This is preliminary information about an Embraer EMB-500/Phenom 100 twin-engine jet that crashed one mile north of the Montgomery County Airport, Gaithersburg, MD at 11am today. The aircraft was on approach to Runway 14 at the airport when the accident occurred. Please contact local authorities for information on passengers and the situation on the ground. The FAA will investigate. We will update this statement when new information is available. \" \\n \\n Photo of plane from FlightAware (Photo: FlightAware) \\n \\n An FAA source says the jet was waiting for a much slower single engine aircraft, possibly a Cessna, to make its turn so it could make its approach. That information has not been confirmed by the NTSB. \\n \\n The Montgomery County Air Park is within 1/2 to 3/4 of a mile of the crash. The airport does not have a tower, so communication would have been with Washington Air Traffic Control Section, not the airport. \\n \\n The FAA registry shows that the plane was a corporate Phenom jet with tail number N100EQ. It\\'s registered to Sage Aviation LLC out of Chapel Hill, NC which makes replacement parts for the aviation industry. \\n \\n MORE: Gaithersburg plane crash at Drop Forge Lane, 3 houses suffering some sort of damage, this one the worst @WNEWpic.twitter.com/vihz4k5eYE — JimMacKayWNEW (@JimMacKayWNEW) December 8, 2014 \\n \\n Snouffer School Road was closed between Centerway Road and Goshen Road following the crash. Drivers and pedestrians are being urged to avoid the area. It is likely to remain closed throughout the night and possibly Tuesday. \\n \\n She says something has to be done about planes flying low directly over homes. \\n \\n Read or Share this story: http://on.wusa9.com/1A8PzKE'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['document'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\ariel\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import HfAgent\n",
    "agent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Explanation from the agent==\n",
      "I will use the following  tool: `summarizer` to create a summary of the input text.\n",
      "\n",
      "\n",
      "==Code generated by the agent==\n",
      "summarized_text = summarizer(text)\n",
      "print(f\"Summary: {summarized_text}\")\n",
      "\n",
      "\n",
      "==Result==\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Please install accelerate in order to use this tool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ariel\\Documents\\PhD Main Folder\\Year 1\\artificial-languages\\testing.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m 1. Crocodiles are 10 meters long\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m2. The scales of crocodiles are green and tough\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m3. The longest crocodile is 15 meters long, but on average they can reach 10 meters.\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m4. From head to tip, crocodiles can measure ten meters\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#%%\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mSummarize the following \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m using two lines or less\u001b[39;49m\u001b[39m\"\u001b[39;49m, text \u001b[39m=\u001b[39;49m text)\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\transformers\\tools\\agents.py:349\u001b[0m, in \u001b[0;36mAgent.run\u001b[1;34m(self, task, return_code, remote, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_code:\n\u001b[0;32m    348\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m==Result==\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_tools \u001b[39m=\u001b[39m resolve_tools(code, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoolbox, remote\u001b[39m=\u001b[39;49mremote, cached_tools\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcached_tools)\n\u001b[0;32m    350\u001b[0m     \u001b[39mreturn\u001b[39;00m evaluate(code, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_tools, state\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mcopy())\n\u001b[0;32m    351\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\transformers\\tools\\agents.py:141\u001b[0m, in \u001b[0;36mresolve_tools\u001b[1;34m(code, toolbox, remote, cached_tools)\u001b[0m\n\u001b[0;32m    139\u001b[0m         task_or_repo_id \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39mtask \u001b[39mif\u001b[39;00m tool\u001b[39m.\u001b[39mrepo_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m tool\u001b[39m.\u001b[39mrepo_id\n\u001b[0;32m    140\u001b[0m         _remote \u001b[39m=\u001b[39m remote \u001b[39mand\u001b[39;00m supports_remote(task_or_repo_id)\n\u001b[1;32m--> 141\u001b[0m         resolved_tools[name] \u001b[39m=\u001b[39m load_tool(task_or_repo_id, remote\u001b[39m=\u001b[39;49m_remote)\n\u001b[0;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m resolved_tools\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\transformers\\tools\\base.py:688\u001b[0m, in \u001b[0;36mload_tool\u001b[1;34m(task_or_repo_id, model_repo_id, remote, token, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[39mreturn\u001b[39;00m RemoteTool(model_repo_id, token\u001b[39m=\u001b[39mtoken, tool_class\u001b[39m=\u001b[39mtool_class)\n\u001b[0;32m    687\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 688\u001b[0m         \u001b[39mreturn\u001b[39;00m tool_class(model_repo_id, token\u001b[39m=\u001b[39mtoken, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    690\u001b[0m     \u001b[39mreturn\u001b[39;00m Tool\u001b[39m.\u001b[39mfrom_hub(task_or_repo_id, model_repo_id\u001b[39m=\u001b[39mmodel_repo_id, token\u001b[39m=\u001b[39mtoken, remote\u001b[39m=\u001b[39mremote, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\transformers\\tools\\base.py:491\u001b[0m, in \u001b[0;36mPipelineTool.__init__\u001b[1;34m(self, model, pre_processor, post_processor, device, device_map, model_kwargs, token, **hub_kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease install torch in order to use this tool.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    490\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m--> 491\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease install accelerate in order to use this tool.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    493\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_checkpoint \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: Please install accelerate in order to use this tool."
     ]
    }
   ],
   "source": [
    "text = \"\"\" 1. Crocodiles are 10 meters long\n",
    "2. The scales of crocodiles are green and tough\n",
    "3. The longest crocodile is 15 meters long, but on average they can reach 10 meters.\n",
    "4. From head to tip, crocodiles can measure ten meters\n",
    "\"\"\"\n",
    "#%%\n",
    "agent.run(\"Summarize the following 'text' using two lines or less\", text = text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tree_map_only' from 'torch.utils._pytree' (c:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\utils\\_pytree.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ariel\\Documents\\PhD Main Folder\\Year 1\\artificial-languages\\testing.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ariel/Documents/PhD%20Main%20Folder/Year%201/artificial-languages/testing.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maccelerate\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\accelerate\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.23.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maccelerator\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbig_modeling\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     cpu_offload,\n\u001b[0;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m skip_first_batches\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\accelerate\\accelerator.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhooks\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhooks\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcheckpointing\u001b[39;00m \u001b[39mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m get_logger\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\accelerate\\checkpointing.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m GradScaler\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     MODEL_NAME,\n\u001b[0;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[0;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[0;32m     28\u001b[0m     SCALER_NAME,\n\u001b[0;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[0;32m     30\u001b[0m     get_pretty_name,\n\u001b[0;32m     31\u001b[0m     is_tpu_available,\n\u001b[0;32m     32\u001b[0m     is_xpu_available,\n\u001b[0;32m     33\u001b[0m     save,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[39mif\u001b[39;00m is_tpu_available(check_device\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     38\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch_xla\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxla_model\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxm\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\accelerate\\utils\\__init__.py:137\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeepspeed\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    128\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[0;32m    129\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m         HfDeepSpeedConfig,\n\u001b[0;32m    134\u001b[0m     )\n\u001b[0;32m    136\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbnb\u001b[39;00m \u001b[39mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[1;32m--> 137\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfsdp_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer\n\u001b[0;32m    138\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlaunch\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    139\u001b[0m     PrepareForLaunch,\n\u001b[0;32m    140\u001b[0m     _filter_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     prepare_tpu,\n\u001b[0;32m    146\u001b[0m )\n\u001b[0;32m    147\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmegatron_lm\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    148\u001b[0m     AbstractTrainStep,\n\u001b[0;32m    149\u001b[0m     BertTrainStep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m     gather_across_data_parallel_groups,\n\u001b[0;32m    159\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\accelerate\\utils\\fsdp_utils.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m is_torch_version\n\u001b[0;32m     24\u001b[0m \u001b[39mif\u001b[39;00m is_torch_version(\u001b[39m\"\u001b[39m\u001b[39m>=\u001b[39m\u001b[39m\"\u001b[39m, FSDP_PYTORCH_VERSION) \u001b[39mand\u001b[39;00m is_torch_distributed_available():\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdist_cp\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdefault_planner\u001b[39;00m \u001b[39mimport\u001b[39;00m DefaultLoadPlanner, DefaultSavePlanner\n\u001b[0;32m     27\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer\u001b[39;00m \u001b[39mimport\u001b[39;00m load_sharded_optimizer_state_dict\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\distributed\\checkpoint\\__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     TensorStorageMetadata,\n\u001b[0;32m      3\u001b[0m     BytesStorageMetadata,\n\u001b[0;32m      4\u001b[0m     ChunkStorageMetadata,\n\u001b[0;32m      5\u001b[0m     Metadata,\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mstate_dict_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m load_state_dict\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mstate_dict_saver\u001b[39;00m \u001b[39mimport\u001b[39;00m save_state_dict\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mimport\u001b[39;00m StorageReader, StorageWriter\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\distributed\\checkpoint\\state_dict_loader.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     StorageReader,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mplanner\u001b[39;00m \u001b[39mimport\u001b[39;00m LoadPlanner\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdefault_planner\u001b[39;00m \u001b[39mimport\u001b[39;00m DefaultLoadPlanner\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _DistWrapper\n\u001b[0;32m     14\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mload_state_dict\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\distributed\\checkpoint\\default_planner.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_shard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m narrow_tensor_by_index\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m DTensor\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplanner\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     SavePlanner,\n\u001b[0;32m     19\u001b[0m     LoadPlanner,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     WriteItemType,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     BytesStorageMetadata,\n\u001b[0;32m     29\u001b[0m     ChunkStorageMetadata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     STORAGE_TYPES,\n\u001b[0;32m     35\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\distributed\\_tensor\\__init__.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Import all builtin dist tensor ops\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrandom\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m compute_local_shape\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\distributed\\_tensor\\ops\\__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39membedding_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmatrix_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmath_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\distributed\\_tensor\\ops\\embedding_ops.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# implement matrix related ops for distributed tensor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mop_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m OpSchema, OutputSharding\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m register_prop_rule\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplacement_types\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     _Partial,\n\u001b[0;32m     10\u001b[0m     DTensorSpec,\n\u001b[0;32m     11\u001b[0m     Replicate,\n\u001b[0;32m     12\u001b[0m     Shard,\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\distributed\\_tensor\\op_schema.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Dict, List, Optional, Sequence, Tuple, Union\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplacement_types\u001b[39;00m \u001b[39mimport\u001b[39;00m DTensorSpec\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pytree\u001b[39;00m \u001b[39mimport\u001b[39;00m tree_map_only, TreeSpec\n\u001b[0;32m      9\u001b[0m \u001b[39m# Common type aliases\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\distributed\\_tensor\\placement_types.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m cast, List, Optional, Tuple\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functional_collectives\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mfuncol\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed_c10d\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mc10d\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tensor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_collective_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m mesh_broadcast, mesh_scatter\n",
      "File \u001b[1;32mc:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\distributed\\_functional_collectives.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed_c10d\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mc10d\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Tuple, Union, List, cast, TYPE_CHECKING\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pytree\u001b[39;00m \u001b[39mimport\u001b[39;00m tree_map_only\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _functional_collectives_impl \u001b[39mas\u001b[39;00m fun_col_impl\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_functional_collectives_impl\u001b[39;00m \u001b[39mimport\u001b[39;00m _register_tensor_wrapper\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'tree_map_only' from 'torch.utils._pytree' (c:\\Users\\ariel\\anaconda3\\lib\\site-packages\\torch\\utils\\_pytree.py)"
     ]
    }
   ],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
